V3I-STAL: Visual Vehicle-to-Vehicle Interaction via Simultaneous Tracking and Localization,"This paper investigates a visual interaction system for vehicle-to-vehicle (V2V) platform, called V3I. Our system employs common visual cameras that are mounted on connected vehicles to perceive the existence of isolated vehicles in the same roadway, and provides human drivers with imagery situational awareness. This allows effective interactions between vehicles even with a low permeation rate of V2V devices. The underlying research problem for V3I includes two aspects: i) tracking isolated vehicles of interest over time through local cameras; ii) at each time-step fusing the results of local visual perceptions to obtain a global location map that involves both isolated and connected vehicles. In this paper, we introduce a unified probabilistic approach to solve the above two problems, i.e., tracking and localization, in a joint fashion. Our approach will explore both the visual features of individual vehicles in images and the pair-wise spatial relationships between vehicles. We develop a fast Markov Chain Monte Carlo (MCMC) algorithm to search the joint solution space efficiently, which enables real-time application. To evaluate the performance of the proposed approach, we collect and annotate a set of video sequences captured with a group of vehicle-resident cameras. Extensive experiments with comparisons clearly demonstrate that the proposed V3I approach can precisely recover the dynamic location map of the surrounding and thus enable direct visual interactions between vehicles ."
Are Safer Looking Neighborhoods More Lively?: A Multimodal Investigation into Urban Life,"Policy makers, urban planners, architects, sociologists, and economists are interested in creating urban areas that are both lively and safe. But are the safety and liveliness of neighborhoods independent characteristics? Or are they just two sides of the same coin? In a world where people avoid unsafe looking places, neighborhoods that look unsafe will be less lively, and will fail to harness the natural surveillance of human activity. But in a world where the preference for safe looking neighborhoods is small, the connection between the perception of safety and liveliness will be either weak or nonexistent. In this paper we explore the connection between the levels of activity and the perception of safety of neighborhoods in two major Italian cities by combining mobile phone data (as a proxy for activity or liveliness) with scores of perceived safety estimated using a Convolutional Neural Network trained on a dataset of Google Street View images scored using a crowdsourced visual perception survey. We find that: (i) safer looking neighborhoods are more active than what is expected from their population density, employee density, and distance to the city centre; and (ii) that the correlation between appearance of safety and activity is positive, strong, and significant, for females and people over 50, but negative for people under 30, suggesting that the behavioral impact of perception depends on the demographic of the population. Finally, we use occlusion techniques to identify the urban features that contribute to the appearance of safety, finding that greenery and street facing windows contribute to a positive appearance of safety (in agreement with Oscar Newman's defensible space theory). These results suggest that urban appearance modulates levels of human activity and, consequently, a neighborhood's rate of natural surveillance."
Detecting Sarcasm in Multimodal Social Platforms,"Sarcasm is a peculiar form of sentiment expression, where the surface sentiment differs from the implied sentiment. The detection of sarcasm in social media platforms has been applied in the past mainly to textual utterances where lexical indicators (such as interjections and intensifiers), linguistic markers, and contextual information (such as user profiles, or past conversations) were used to detect the sarcastic tone. However, modern social media platforms allow to create multimodal messages where audiovisual content is integrated with the text, making the analysis of a mode in isolation partial. In our work, we first study the relationship between the textual and visual aspects in multimodal posts from three major social media platforms, i.e., Instagram, Tumblr and Twitter, and we run a crowdsourcing task to quantify the extent to which images are perceived as necessary by human annotators. Moreover, we propose two different computational frameworks to detect sarcasm that integrate the textual and visual modalities. The first approach exploits visual semantics trained on an external dataset, and concatenates the semantics features with state-of-the-art textual features. The second method adapts a visual neural network initialized with parameters trained on ImageNet to multimodal sarcastic posts. Results show the positive effect of combining modalities for the detection of sarcasm across platforms and methods."
User Redirection and Direct Haptics in Virtual Environments,"This paper proposes a haptic interaction system for Virtual Reality (VR) based on a combination of tracking devices for hands and objects and a real-to-virtual mapping system for user redirection. In our solution the user receives haptic stimuli by manipulating real objects mapped to virtual ob- jects. This solution departs from systems that rely on haptic devices (e.g., haptic gloves) as interfaces for the user to inter- act with objects in the Virtual Environment (VE). As such, the proposed solution makes use of direct haptics (touching) and redirection techniques to guide the user through the vir- tual environment. Using the mapping framework, when the user touches a virtual object in the VE, he will simultane- ously be physically touching the equivalent real object. A relevant feature of the framework is the possibility to de- fine a warped mapping between the real and virtual worlds, such that the relation between the user and the virtual space can be different from the one between the user and the real space. This is particularly useful when the application re- quires the emulation of large virtual spaces but the physical space available is more confined. To achieve this, both the user's hands and the objects are tracked. In the presented prototype we use a head-mounted depth sensor (i.e., Leap Motion) and a depth-sensing camera (i.e., Kinect). To assess the feasibility of this solution, a functional prototype and a room setup with core functionality were implemented. The test sessions with users evaluated the mapping accuracy, the user execution time and the awareness of the user regarding the warped space when performing tasks with redirection. The results gathered indicate that the solution can be used to provide direct haptic feedback in VR applications and for warping space perception within certain limits."
