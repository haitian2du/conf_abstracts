DARE: Dynamic Adaptive Mobile Augmented Reality with Edge Computing.,"Mobile augmented reality (MAR) is a killer application of mobile edge computing because of its high computation demand and stringent latency requirement. Since edge networks and computing resources are highly dynamic, handling such dynamics is essential for providing high-quality MAR services. In this paper, we design a new network protocol named DARE (dynamic adaptive AR over the edge) that enables mobile users to dynamically change their AR configurations according to wireless channel conditions and computation workloads in edge servers. The dynamic configuration adaptations reduce the service latency of MAR users and maximize the quality of augmentation (QoA) under varying network conditions and computation workloads. Considering the video frame size and computation model, i.e., object detection algorithms, as two key parameters in adapting the AR configuration, we develop analytical models to characterize the impact of these parameters on QoA and the service latency. Then, we design optimization mechanisms on both the edge server and AR devices to guide the AR configuration adaptation and server computation resource allocation. The performance of the DARE protocol is validated through a small-scale testbed implementation."
IoTm: A Lightweight Framework for Fine-Grained Measurements of IoT Performance Metrics.,"Most Internet of Things (IoT) applications require unique guarantees on various performance metrics (such as latency, CPU availability, power fairness, etc.) from the IoT infrastructure. A small deterioration in these performance metrics can cause serious violations of service level agreements. To ensure that the deployed IoT infrastructure delivers the guarantees on these metrics, the first step is to measure these metrics. We present IoTm, a framework for measuring IoT performance metrics, which include both IoT network's quality of service (QoS) metrics and IoT node's resource utilization (RU) metrics. IoTm has two key properties: 1) it is lightweight and thus amenable for implementation on resource constrained IoT nodes; and 2) it can perform measurements at fine-grained levels and not just at aggregate levels. IoTm is comprised of two components, a lightweight IoT node unit (INU), which resides in each of the IoT nodes, and a control and query unit (CQU), which resides in a logically centralized management server. The primary role of INU is to record appropriate information about the desired performance metrics in the IoT nodes. To record the information, INU leverages a generic data structure that we propose. CQU is responsible for identifying the metrics and the IoT nodes on which those metrics should be monitored to achieve a desired measurement objective. CQU also stores the copies of data structures that the INU sends to it for long term storage. Both INU and CQU further contain query processing engines, which operate on the information stored in the data structures to answer measurement queries. To demonstrate the use of our framework, we apply it to one RU metric (number of disk accesses), and one QoS metric (round trip latency), and evaluate its accuracy. We also analyze the feasibility of its implementation on IoT nodes in terms of memory requirement and computational complexity."
Dynamic Heterogeneity-Aware Coded Cooperative Computation at the Edge.,"Cooperative computation is a promising approach for localized data processing at the edge, e.g., for Internet of Things (IoT). Cooperative computation advocates that computationally intensive tasks in a device could be divided into sub-tasks, and offloaded to other devices or servers in close proximity. However, exploiting the potential of cooperative computation is challenging mainly due to the heterogeneous and time-varying nature of edge devices. Coded computation, which advocates mixing data in sub-tasks by employing erasure codes and offloading these sub-tasks to other devices for computation, is recently gaining interest, thanks to its higher reliability, smaller delay, and lower communication costs. In this paper, we develop a coded cooperative computation framework, which we name Coded Cooperative Computation Protocol (C3P), by taking into account the heterogeneous resources of edge devices. C3P dynamically offloads coded sub-tasks to helpers and is adaptive to time-varying resources. We show that (i) task completion delay of C3P is very close to optimal coded cooperative computation solutions, (ii) the efficiency of C3P in terms of resource utilization is higher than 99%, (iii) C3P improves task completion delay significantly as compared to baselines via both simulations and in a test-bed consisting of real Android-based smartphones."
JamCloak: Reactive Jamming Attack over Cross-Technology Communication Links.,"Recently, CTC (Cross-Technology Communication), allowing the direct communication among heterogeneous devices with incompatible physical layers, has attracted much research attention. Many efficient CTC protocols have been proposed to demonstrate its promise in IoT applications. However, the applications built upon CTC will be significantly impaired when CTC suffers from malicious attacks such as jamming or sniffing. In this paper, we implement a reactive jamming system, JamCloak, that can attack most existing CTC protocols. To this end, we first propose a taxonomy of the existing CTC protocols. Then based on the taxonomy, we extract essential features to train a CTC detection model, and estimate the parameters that can efficiently jam CTC links. Experimental results show that JamCloak consistently achieves 94.7% of classification accuracy on average in both LoS (Line-of-Sight) and NLoS (Non-Line-of-Sight) scenarios. We also apply JamCloak to attack three existing CTC protocols: WiZig, Esense and EMF. Results show that JamCloak can significantly reduce PDR (packet delivery ratio) by 80.8% on average in practical environments. In the meantime, JamCloak's jamming gain is more than 1.78Ã— higher than the existing reactive jammer. In addition, we propose a practical countermeasure against reactive jamming attack over CTC links like JamCloak. Results show that our approach significantly improves the jamming detection accuracy by 91.2% on average than the existing approach, and effectively decreases the reduction in packet delivery ratio to 1.7%."
"Sybil Detection in Social-Activity Networks: Modeling, Algorithms and Evaluations.","Detecting fake accounts (sybils) in online social networks (OSNs) is vital to protect OSN operators and their users from various malicious activities. Typical graph-based sybil detection (a mainstream methodology) assumes that sybils can make friends with only a limited (or small) number of honest users. However, recent evidences showed that this assumption does not hold in real-world OSNs, leading to low detection accuracy. To address this challenge, we explore users' activities to assist sybil detection. The intuition is that honest users are much more selective in choosing who to interact with than to befriend with. We first develop the social and activity network (SAN), a two-layer hyper-graph that unifies users' friendships and their activities, to fully utilize users' activities. We also propose a more practical sybil attack model, where sybils can launch both friendship attacks and activity attacks. We then design Sybil SAN to detect sybils via coupling three random walk-based algorithms on the SAN, and prove the convergence of Sybil SAN. We develop an efficient iterative algorithm to compute the detection metric for Sybil SAN, and derive the number of rounds needed to guarantee the convergence. We use ""matrix perturbation theory"" to bound the detection error when sybils launch many friendship attacks and activity attacks. Extensive experiments on both synthetic and real-world datasets show that Sybil SAN is highly robust against sybil attacks, and can detect sybils accurately under practical scenarios, where current state-of-art sybil defenses have low accuracy."
A Fair Consensus Protocol for Transaction Ordering.,"We present Helix, a blockchain-based consensus protocol for fair ordering of transactions among nodes in a distributed network. Helix advances in rounds, where in each round, the primary node (elected among the network nodes) proposes a potential block (a successive set of transactions). In order to be included in the blockchain, a block must pass validation by an elected committee of nodes. Helix nodes are presumed to have two primary preferences. They prefer to be elected as committee members. Additionally, because each transaction is associated with one of the network nodes, they prefer to prioritize their own transactions over those of others. In light of these individual preferences, our definition of fairness incorporates three key elements. First, the process of electing nodes to committees is random and unpredictable. Second, a correlated sampling scheme is used in order to guarantee random selection and ordering of pending transactions in blocks. Third, transactions are encrypted in order to hide their associations with their respective nodes and prevent censorship. Through the corresponding threshold decryption process we obtain an unpredictable and non-manipulable randomness beacon, which serves both the election process and the correlated sampling scheme. We define a quantitative measure of fairness in the protocol, prove theoretically that fairness manipulation in Helix is significantly limited, and present experiments evaluating fairness in practice."
QDAPS: Queueing Delay Aware Packet Spraying for Load Balancing in Data Center.,"Modern data center networks are usually constructed in multi-rooted tree topologies, which require the highly efficient multi-path load balancing to achieve high link utilization. Recent packet-level load balancer obtains high throughput by spraying packets to all paths, but it easily leads to the packet reordering under network asymmetry. The flow-level or flowlet-level load balancer avoids the packet reordering, while reducing the link utilization due to their inflexibility. To solve these problems, we design a Queueing Delay Aware Packet Spraying (QDAPS), that effectively mitigates the packet reordering for packet-level load balancer. QDAPS selects paths for packets according to the queueing delay of output buffer, and lets the packet arriving earlier be forwarded before the later packets to avoid packet reordering. We compare QDAPS with ECMP, LetFlow and RPS through NS2 simulation and Mininet implementation. The test results show that QDAPS reduces flow completion time (FCT) by ~30%-50% over the state-of-the-art load balancing mechanism."
Republic: Data Multicast Meets Hybrid Rack-Level Interconnections in Data Center.,"Data multicast is a crucial data transfer pattern in distributed big-data processing. However, due to the lack of network and system level support, data processing relies on unicast-based application layer multicast. In recent years, there has been a surge in interest in using various emerging circuit switching technologies to build data centers having hybrid packet-circuit switched rack-level interconnections, i.e., hybrid data centers. These physical layer innovations fundamentally change the inter-rack communication capability, especially the capability of multicast communication. We propose Republic, a complete system that addresses the challenging issues in achieving high-performance data multicast in hybrid data centers. Republic abstracts the underlying network complexity as a data multicast service and provides a unified Republic API for data center applications requesting data multicast. Republic is implemented and deployed in a hybrid data center testbed. Testbed evaluation shows that Republic can improve data multicast in Apache Spark machine learning applications by as much as 4.0x."
"Micro-Burst in Data Centers: Observations, Analysis, and Mitigations.","Micro-burst traffic is not uncommon in data centers. It can cause packet dropping, which results in serious performance degradation (e.g., Incast problem). However, current solutions that attempt to suppress micro-burst traffic are extrinsic and ad hoc, since they lack the comprehensive and essential understanding of micro-burst's root cause and dynamic behavior. On the other hand, traditional studies focus on traffic burstiness in a single flow, while in data centers micro-burst traffic could occur with highly fan-in communication pattern, and its dynamic behavior is still unclear. To this end, in this paper, we re-examine the microburst traffic in typical data center scenarios. We find that evolution of micro-burst is determined by both TCP's self-clocking mechanism and bottleneck link. Besides, dynamic behaviors of micro-burst under various scenarios can all be described by the slope of queue length evolution. Our observations also implicate that conventional solutions like absorbing and pacing are ineffective to mitigate micro-burst traffic. Instead, senders need to slow down as soon as possible. Inspired by the findings and insights from experimental observations, we propose S-ECN policy, which is an ECN marking policy leveraging the slope of queue length evolution. Transport protocols utilizing S-ECN policy can suppress the sharp queue length increment by over 2Ã—, and reduce the average query completion time by ~12-27%."
DCQCN+: Taming Large-Scale Incast Congestion in RDMA over Ethernet Networks.,"Remote Direct Memory Access (RDMA) gains growing popularity in datacenter networks. The state-of-the-art congestion control scheme is DCQCN. However, DCQCN has performance problems when large-scale incast communication happens. DCQCN uses fixed period and steps for rate increase when probing for available bandwidth and this scheme is not scalable. Our key insight is that: senders should be aware of the scale of each incast, so that they can adjust their aggressiveness accordingly. The challenges come from different aspects. The scale of congestion is not easy to estimate while the control scheme should be cautiously designed. In this paper, we propose DCQCN+ to improve performance for large-scale incast congestion in RDMA networks. DCQCN+ adapts the rate control mechanisms to different scenarios. DCQCN+ can deal with incast congestion of at least 2,000 flows both in simulation and testbed. The scale is 10 times larger than that of DCQCN in simulation and 4 times larger in testbed. DCQCN+ also has 10 times smaller latency."
New Alternatives to Optimize Policy Classifiers.,"Growing expressiveness of services increases the size of a manageable state at the network data plane. A service policy is an ordered set of classification patterns (classes) with actions; the same class can appear in multiple policies. Previous studies mostly concentrated on efficient representations of a single policy instance. In this work, we study space efficiency of multiple policies, cutting down a classifier size by sharing instances of classes between policies that contain them. In this paper we identify conditions for such sharing, propose efficient algorithms and analyze them analytically. The proposed representations can be deployed transparently on existing packet processing engines. Our results are supported by extensive evaluations."
Virtual Network Function Deployment in Tree-Structured Networks.,"Network Function Virtualization (NFV) evolves the implementation of network functions from expensive hardwares to software middleboxes. These software middleboxes, also called Virtual Network Functions (VNFs), are executed on switch-connected servers. Efficiently deploying such VNFs is challenging, because VNFs must fully process all flows with their traffic rates before they reach their destinations while VNF locations are restricted by the constraint of vertex capacity. In addition, each network function offers heterogeneous VNF types with different configurations of processing volumes and costs. This paper focuses on minimizing the total cost of deploying VNF instances for providing a specific network function to all flows in tree-structured networks. First we prove the NP-hardness of heterogeneous VNF deployment in a tree topology and propose a dynamic programming based solution with a pseudo-polynomial time complexity. Then we narrow down to three simplified cases by focusing on homogeneous VNFs or the linear line topology. Specifically, three algorithms are introduced: an improved dynamic programming based algorithm for deploying homogeneous VNFs in a tree topology, a performance-guaranteed algorithm for deploying heterogeneous VNFs in a linear line topology, and an optimal greedy algorithm for deploying homogeneous VNFs in a linear line topology. Extensive simulations are conducted to evaluate the performance of our algorithms."
CADIA: Towards Decoupling the Congestion Control for Multipath TCP.,"Correlating the congestion control (CC) of parallel subflows of multipath TCP (MPTCP) has shown the advantage of making it fair and friendly to legacy TCP. But the correlation also leads to some new drawbacks. In this paper, we first analyze major correlated MPTCP CC algorithms through the perspective of bandwidth competition. Based on the modeling, we verify, discover, and explain three shortages of correlated CC, namely 1) limit fairness semantic; 2) render new attack surfaces; and 3) interplay with network sharing policies. We further find that decoupling the CC of subflows is more promising in solving the above issues. However, directly applying legacy TCP CC to each subflow independently would lose the benefits of correlated CC. This motivates the design of an algorithm that decouples the CC of subflows as much as possible while still making MPTCP fair and friendly. To attain this goal, we translate the goals of correlated CC into an approximation principle under the decoupled semantic. We then propose a self-Constrained And Decoupled Increase Algorithm (CADIA) that achieves the principle by adaptively detecting and constraining non-best subflows. This makes CADIA share the benefits of correlated CC algorithms, while owning no direct correlation among the CC of subflows. Extensive analysis and experiments are conducted to demonstrate the effectiveness of CADIA."
Grus: Enabling Latency SLOs for GPU-Accelerated NFV Systems.,"Graphics Processing Unit (GPU) has been recently exploited as a hardware accelerator to improve the performance of Network Function Virtualization (NFV). However, GPU-accelerated NFV systems suffer from significant latency variation when multiple network functions (NFs) are co-located in the same machine, which prevents operators from supporting latency Service Level Objectives (SLOs). Existing research efforts to address this problem can only guarantee a limited number of SLOs with very low resource utilization efficiency. In this paper, we present the Grus framework to support latency SLOs in GPU-accelerated NFV systems. Grus thoroughly analyzes the sources of latency variation and proposes three design principles: (1) dynamic batch size setting is needed to bound packet batching latency in CPU; (2) a reordering mechanism for data transfer over PCI-E is required to guarantee the stalling time; and (3) maximizing concurrency in GPU is necessary to avoid NF execution waiting time. Guided by the principles, Grus consists of two logical layers including an infrastructure layer and a scheduling layer. The infrastructure layer is equipped with an in-CPU Reorder-able Worker Pool that could adjust batching size and packet transfer order, and in-GPU Controllable Concurrent Executors to provide maximized concurrency. The scheduling layer runs a heuristic algorithm to perform accurate and fast scheduling to guarantee SLOs based on our prediction models. We have implemented a prototype of Grus. Extensive evaluations demonstrate that Grus can significantly reduce latency variation and satisfy 4.5 Ã— more SLO terms than state-of-the-art solutions."
HotDASH: Hotspot Aware Adaptive Video Streaming Using Deep Reinforcement Learning.,"A large fraction of video content providers have adopted adaptive bitrate streaming over HTTP. The client player typically runs an adaptive bitrate (ABR) algorithm to decide upon the most optimal quality for the next few seconds of video playback. State-of-the-art ABR algorithms attempt to achieve an optimal trade-off among the competing objectives of high bitrate, less rebuffering, and high smoothness, in the face of unpredictable bandwidth variability. However, optimal bandwidth utilization does not necessarily ensure high quality of experience (QoE). Different users have different content preferences even within the same video, due to differences in team loyalties (in sport), character preferences (in movies and soaps), and so on. In this work, we present HotDASH, a system which enables opportune prefetching of user-preferred temporal video segments (called hotspots). HotDASH implements a prefetch module in the open source DASH player dash.js, which is powered by an optimal prefetch and bitrate decision engine. The decision engine is designed as a cascaded reinforcement learning (RL) model, implemented using a state-of-the-art actor-critic RL algorithm over a neural network. We train the neural network using trace-driven simulations over a large variety of bandwidth conditions. HotDASH outperforms all baseline algorithms, with a 16.2% QoE improvement over the best-performing baseline, and achieves 14.31% better average bitrate due to its ability to prefetch opportunistically."
Ares: A High Performance and Fault-Tolerant Distributed Stream Processing System.,"Distributed Stream Processing Systems (DSPSs) have been widely deployed to process infinite data streams. Short processing latency and short recovery time are both vital for many DSPS applications. Existing DSPS designs commonly leverage elaborated task allocation strategies to achieve short processing latency. Such designs, however, ignore the requirement of system fault tolerance. Indeed, providing fault tolerant capability in a DSPS can cause significant degradation of system performance. Especially, the intrinsic dependency between upstream and down-stream tasks can incur cascaded waiting during recovery, leading to prohibitively long recovery time. In this paper, we propose Ares, a high performance and fault tolerant DSPS. Ares considers both system performance and fault tolerant capability during task allocation. In the design of Ares, we formalize the problem of Fault Tolerant Scheduler (FTS) for finding an optimal task allocation which maximizes the system utility. We use a game-theoretic approach to solve the FTS problem and propose a novel Nirvana algorithm based on best-response dynamics. We mathematically prove the existence of Nash equilibrium in the FTS game. We implement Ares atop Apache Storm and conduct comprehensive experiments to evaluate this design. The results show that, compared to existing designs Ares achieves a 3.6Ã— improvement of throughput, as well as reducing the processing latency and the recovery time by 50.2% and 52.5%, respectively."
RPC: Joint Online Reducer Placement and Coflow Bandwidth Scheduling for Clusters.,"Reducing Coflow Completion Time (CCT) has a significant impact on application performance in data-parallel frameworks. Most existing works assume that the endpoints of constituent flows in each coflow are predetermined. We argue that CCT can be further optimized by treating flows' destinations as an additional optimization dimension via reducer placement. In this paper, we propose and implement RPC, a joint online Reducer Placement and Coflow bandwidth scheduling framework, to minimize the average CCT in cloud clusters. We first develop a 2-approximation algorithm to minimize the CCT of a single coflow, then schedule all the coflows following the Shortest Remaining Time First (SRTF) principle. We use a real testbed implementation and extensive large-scale simulations to demonstrate that RPC can reduce the average CCT by 64.98% compared with state-of-the-art technologies."
Cuttlefish: Hierarchical SDN Controllers with Adaptive Offload.,"Offloading computation to local controllers (closer to switches) has been a popular approach to designing scalable SDN controllers. We observe that, in addition to the offload of local switch-specific state, a subset of global state can also be offloaded to, and accessed at local controllers with suitable synchronization. We present the design and implementation of Cuttlefish, an SDN controller framework that adaptively offloads a portion of the application state (and computation) to local controllers. Cuttlefish uses developer-specified input to identify control messages that can be correctly processed at local controllers, and makes offloading decisions based on the cost of synchronizing the offloaded state across controllers. SDN applications use the Cuttlefish API to access the offloaded state, and Cuttlefish transparently manages the state synchronization, and redirection of control messages to the appropriate (central or local) controller. We have implemented Cuttlefish using the Floodlight SDN controller. Our evaluation shows that Cuttlefish applications achieve ~2X higher control plane throughput and ~50% lower control plane latency as compared to the traditional SDN design."
On SDN-Enabled Online and Dynamic Bandwidth Allocation for Stream Analytics.,"Data communication in cloud-based distributed stream data analytics often involves a collection of parallel and pipelined TCP flows. As the standard TCP congestion control mechanism is designed for achieving ""fairness"" among competing flows and is agnostic to the application layer contexts, the bandwidth allocation among a set of TCP flows traversing bottleneck links often leads to sub-optimal application-layer performance measures, e.g., stream processing throughput or average tuple complete latency. Motivated by this and enabled by the rapid development of the Software-Defined Networking (SDN) techniques, in this paper, we re-investigate the design space of the bandwidth allocation problem and propose a cross-layer framework which utilizes the additional information obtained from the application layer and provides on-the-fly and dynamic bandwidth adjustment algorithms for helping the stream analytics applications achieving better performance during the runtime. We implement a prototype cross-layer bandwidth allocation framework based on a popular open-source distributed stream processing platform, Apache Storm, together with the OpenDaylight controller, and carry out extensive experiments with real-world analytical workloads on top of a local cluster consisting of 10 workstations interconnected by a SDN-enabled switch. The experiment results clearly validate the effectiveness and efficiency of our proposed framework and algorithms."
INDAGO: A New Framework For Detecting Malicious SDN Applications.,"Software-Defined Networking (SDN) controllers not only provide centralized control of SDNs, but also implement open and programmable APIs to ultimately establish an open network environment, where anyone can develop and deliver useful SDN applications. In such an environment, malicious SDN applications can be easily developed and distributed by untrusted entities and can even possess full control of SDNs. Thus, the security threat of malicious SDN applications must be taken seriously. In this paper, we propose a novel system, called Indago, which statically analyzes SDN applications to model their behavioral profiles, and finally, it automatically detects malicious SDN applications with a machine learning approach. We implement a prototype system and evaluate its effectiveness with real world SDN applications and malware. Our evaluation results show that the system can detect most known SDN malware with a high detection rate and low error rates."
Hermes: Utility-Aware Network Update in Software-Defined WANs.,"State-of-the-art inter-datacenter WANs rely on software defined networking (SDN) to orchestrate their data transmission. Optimization requires frequent network update operations to switch forwarding tables. When scheduling inter-datacenter WANs, the utility of services should be respected. Yet, existing network update approaches do not respect network utility and could result in performance degradation during the network update procedure. Further, the update causes not only performance degradation, but also the degradation period is unnecessarily prolonged. In this paper we propose Hermes, a utility-aware network update system. We aim to find a rate limiting scheme for update which maximizes the sum of service utility, while ensuring the congestion-free property during the update. We propose an optimization framework for the maximum utility network update problem (MUP). MUP is NP-hard and a series of algorithms are developed to solve it. Extensive simulation and testbed experiments with a prototype demonstrate that Hermes can increase the total utility by 80% compared to state-of-the-art. At the same time, it reduces the total update time and control overhead by 40% and 55%, respectively."
Stabilizing Chaotic Behavior of RED.,"The Internet is a so complex nonlinear network that many results show how the data flow exhibits chaotic attributes and the fractal nature of aggregate TCP/IP traffic. In this work, we study a new model of Random Early Detection (RED) using beta distribution configured by tuning decisions of dropping or accepting packets so that the queue occupancy level is kept at a given target level, thereby eliminating aggressive fluctuations of buffer underflow and overflow. Our proposed model programmed with Python incorporates new parameters (Î±, Î²) that make it possible to stabilize oscillations of averaged router queue length and to be close to the stationary state. We present study and numerical analysis from the same perspective of former studies for congestion control."
LTSM: Lightweight and Time Sliced Measurement for Link State.,"Link state measurement is the fundamental part of routing control and has received wide attention in research community. However, due to the massive number of network nodes, it is considerably expensive to measure the network timely. In this work, we propose LTSM, a lightweight and time sliced measurement approach for link state to reduce the measurement cost. In LTSM, the measurement tasks are assigned to all nodes evenly and launched at proper time. Theoretically, the measurement cost can be reduced by 50%. We design a prototype of the approach and implement it on a real-world network consisting of 37 public cloud nodes and 1, 332 links. Experimental results show that our approach can acquire the link state of the network efficiently."
Innovating at the Connected Industry: SDN and NFV Experiences and Lessons Learned.,"The aim of this poster is to present the SN4I (Smart Networks for Industry) infrastructure, which will be used to interconnect real machine tools among them and with research laboratories in order to allow experimentation in Industry 4.0 services based on NFV (Network Function Virtualization) and SDN (Software Defined Networking) technologies. In this poster, we present the insights of the SN4I infrastructure as well as the challenges faced during its deployment and the main outcomes achieved so far."
NetVision: Towards Network Telemetry as a Service.,"In-band Network Telemetry (INT) can provide fine-grained and accurate device-level telemetry metrics. Nonetheless, INT can track only a small ratio of devices and links and embedding telemetry data into normal packets brings high overhead and high operation complexity. Hence, we present NetVision, a powerful proactive network telemetry platform with high coverage and high scalability."
In Search of the Lost Nodes in BANs.,"Communication in Body Area Networks (BANs) involves extremely weak signals because of safety regulations. Human mobility adds one more layer of complexity as it has an effect on path loss depending on the activity. In this paper, we improve the quality of service (QoS) by searching for the lost nodes. Specifically, an Emergency Phase (EP) is added after RAP1 of IEEE 802.15.6-2012 superframe. The connected nodes transmit rescue beacons to reach distressed nodes, i.e. nodes that are disconnected. If a distressed node receives a rescue beacon, it participates to the current EP. The packets are buffered and relayed to the hub by the connected nodes. Our results show that when EP is enabled it is feasible to reach more nodes."
Model-Less Approach of Network Traffic for Accurate Packet Loss Simulations.,"It is important to accurately model network traffic when we evaluate Quality of Service (QoS) of networks through simulations. However, for traffic in real networks, it is a tough task to select an appropriate traffic model and tune its parameters. Even if the accurate traffic modeling is achieved, it is also difficult to accurately estimate QoS regarding rare events, such as a packet loss rate in the modern Internet. In this paper, we propose a model-less approach to accurately estimate a packet loss rate through a simulation without directly modeling traffic including real network traffic. We also show the effectiveness of the approach in a simple queueing system as a first step in our development."
ICN Performance Enhancing Proxies for the Global Content Distribution.,"In this paper, we reveal the potential performance degradation in the global content distribution over Information-Centric Networking (ICN), and propose an ICN performance enhancing proxy (PEP) to mitigate this degradation. ICN follows a pull-based communication model, and congestion control is done by the consumer. Due to the fact that the consumer increases its congestion window only with the reception of data packets, it requires some round-trip time (RTT) to send large amount of interests. In the global network, which has a large RTT values, consumer's congestion window is increased slowly, and this leads to low throughput. Here we propose the ICN-PEP that can accelerate the growth of the consumer's congestion window by prefetching future data packets. We evaluated the ICN-PEP performance from the video streaming over the global ICN testbed, and our ICN-PEP could reduce the startup time of video streaming."
Kiram and WOE: Distributed Denial of Service Attacks in Named-Data Networking.,"The current Internet infrastructure, initially conceived to provide closed group connectivity to a limited user-base, is now facing the challenges of catering to over three billion users with dynamically changing data, transport, and access requirements. Content-Centric Networking (CCN) is being explored as a possible future Internet architecture. Named-Data Networking (NDN) exemplifies CCN and with the ever-changing security landscape, it is imperative to build it with intrinsic resilience based on the security by design narrative. In this extended abstract, we explore the fake interest fiooding by adversaries to launch a Distributed Denial of Service (DDoS) attack in NDN. We propose Kiram as an intelligent anomaly recognition and alert generation mechanism serving as a collaborative countermeasure to a DDoS attack. The alert generated by Kiram is named Warding Off Evil (WOE). This poster presents results establishing the effectiveness of Kiram based on substantial simulations over a fairly realistic topology."
Demo Abstract: Themis: Cross-Domain Resource Orchestration and Virtualization in Cellular Computing Networks.,We demonstrate the Themis protocol and its system implementation that realizes cross-domain resource orchestration and virtualization in cellular computing networks.
Networking Support For Physical-Layer Cross-Technology Communication.,"Recent research on physical layer cross technology communication (PHY-CTC) brings a timely answer for escalated wireless coexistence and open spectrum movement. PHY-CTC achieves direct communication among heterogeneous wireless technologies (e.g.,WiFi, Bluetooth, and ZigBee) in physical layer and thus brings communication support for coexistence service such as spectrum management and IoT device control. To put PHY-CTC into service, however, there still exists a gap due to its transmission failure and asymmetric link (i.e., one-way PHYCTC) issues. In this paper, we propose NetCTC - the first networking support design for PHY-CTC to establish feedbacks (e.g., ACKs) and thus meet the upper layer networking requirements in heterogeneous unicast, multicast and broadcast. The core design of NetCTC is a real-time interaction mechanism which achieves reliable, transmission efficient and parallel interactive communication among heterogeneous devices. We implement and evaluate NetCTC on commodity devices (Laptops with Atheros AR2425 WiFi NIC, smart phones with Broadcom BCM4330 WiFi chip and MicaZ CC2420) and the USRP-N210 platform. Our extensive evaluation demonstrates that NetCTC achieves reliable bidirectional cross technology communication under a full range of wireless configurations including stationary, mobile and dutycycled settings."
SIDE: Semi-Distributed Mechanical Equilibrium Based UAV Deployment.,"Recently, we have seen the unprecedented development in unmanned aerial vehicles (UAVs) from different aspects. Accordingly, an increasing number of applications have emerged based on UAVs. Among which, placing UAVs as Aerial Base Stations (ABSs) has received considerable interest in both the industrial and academic community. Existing solutions focus on the optimization of the UAV deployment problem for static user topology using the control information obtained from the Terrestrial Base Station (TBS), that makes hard for the controller to make real-time decisions. To break this stalemate, we propose a SemI-DistributEd system, named SIDE, for the UAV self-deployment. In SIDE, we introduce a mechanical equilibrium based approach, named EMech, via which the UAV positions are self-adapted according to users' attraction (e.g., user distance and traffic demand) within their transmission range. To facilitate the EMech, we propose a fine-grained area splitting strategy, termed KDivision, that partitions the service area in accordance with the user density. Finally, an area merging technique, namely RMerge, is exploited to approximately optimize the positions of the UAVs assisted by an Utility Function that strikes a balance amid the network performance and economic cost. We conduct field experiments to validate the feasibility of EMech. Extensive simulation results show that the proposed SIDE finds the optimal number of assigned UAVs, which not only reduces the cost of the system significantly, but also improves the achievable rate up to 74.6% compared to the existing solutions while consuming almost the same energy level."
ELI: Empowering LTE with Interference Awareness in Unlicensed Spectrum.,"The advent of LTE into the unlicensed spectrum has necessitated the understanding of its operational efficiency when sharing spectrum with different radio access technologies. Our study reveals that LTE, owing to its inherent transmission characteristics, suffers significant performance degradation in the presence of interference caused by hidden terminals. This motivates the need for interference-awareness in LTE's channel access in unlicensed spectrum. To address this problem, we propose ELI. ELI's three-pronged solution equips the LTE base station with novel techniques to: (a) accurately detect and measure interference caused by hidden terminals, (b) collect interference statistics from clients across different channels with affordable overhead, and (c) leverage interference-awareness to improve its channel access performance. Our evaluations show that ELI can achieve 1.5-2x throughput gains over baseline schemes. Finally, ELI is LTE-LAA/MulteFire-standard compliant and can be deployed over the existing LTE-LAA implementation without any modifications."
KeySight: Troubleshooting Programmable Switches via Scalable High-Coverage Behavior Tracking.,"The rise of programmable switches and P4 brings much flexibility to networks, but this flexibility comes with increased risks of bugs. Diagnosing these bugs is essential for network operation but is non-trivial. A potential approach is to track packet behaviors through postcards, but existing tools either generate substantial postcards (limited scalability) or only track a small proportion of packet behaviors (low coverage). In this paper, we present KeySight, a platform that troubleshoots programmable switches with high scalability and high coverage. The key idea is based on the Packet Equivalence Class (PEC) abstraction that aggregates packets with identical behaviors and generates one postcard per behavior. The PEC abstraction minimizes the number of postcards while tracking all packet behaviors. We design novel algorithms to analyze PECs of P4 programs and to implement the PEC abstraction on programmable switches. We deploy KeySight on Tofino and SmartNIC, and evaluate it against 80 P4 programs and real packet traces of over 5TB. Results show that in the premise of overseeing over 99.9% packet behaviors, KeySight reduces the number of postcards by one to two orders of magnitude when comparing with NetSight."
A Fast and Memory-Efficient Trie Structure for Name-Based Packet Forwarding.,"Name lookup is an essential function, but a performance bottleneck in both today's and future network architectures. Variable-length and unbounded names rather than fixed-length addresses, as well as much larger and more dynamic forwarding tables call for a careful re-engineering of lookup structures for fast, memory-efficient, and scalable packet forwarding. We propose a novel data structure, called NameTrie, to store and index forwarding table entries efficiently and to support fast name lookups and updates. Its novelty lies in the optimized design and implementation of a character-trie structure. The nodes of NameTrie are stored compactly, improving cache efficiency and speeding up packet processing. Its edges are implemented using a hash table, facilitating fast name lookups and updates. A new scheme is used to encode control information without consuming additional memory. Running on conventional commodity hardware and using large-scale real-world name datasets, our implementation of NameTrie in software achieves 2.82~3.56, 3.48~3.72, and 2.73~3.25 million name insertions, lookups, and removals per second, respectively, for various datasets while requiring a small memory footprint. We have conducted a comprehensive performance evaluation against the state-of-the-art of named data networking (NDN) as a typical use-case. It is shown to require at least 35% less memory and runs at least 3x faster for name table lookups and updates than two well-known trie-based schemes in NDN."
Efficient Measurement on Programmable Switches Using Probabilistic Recirculation.,"Programmable network switches promise flexibility and high throughput, enabling applications such as load balancing and traffic engineering. Network measurement is a fundamental building block for such applications, including tasks such as the identification of heavy hitters (largest flows) or the detection of traffic changes. However, high-throughput packet processing architectures place certain limitations on the programming model, such as restricted branching, limited capability for memory access, and a limited number of processing stages. These limitations restrict the types of measurement algorithms that can run on programmable switches. In this paper, we focus on the RMT programmable high-throughput switch architecture, and carefully examine its constraints on designing measurement algorithms. We demonstrate our findings while solving the heavy hitter problem. We introduce PRECISION, an algorithm that uses Probabilistic Recirculation to find top flows on a programmable switch. By recirculating a small fraction of packets, PRECISION simplifies the access to stateful memory to conform with RMT limitations and achieves higher accuracy than previous heavy hitter detection algorithms that avoid recirculation. We also analyze the effect of each architectural constraint on the measurement accuracy and provide insights for measurement algorithm designers."
Quantifying Deployability & Evolvability of Future Internet Architectures via Economic Models.,"Emerging new applications demand the current Internet to provide new functionalities. Although many future Internet architectures and protocols have been proposed to fulfill such needs, ISPs have been reluctant to deploy these architectures. We believe technical issues are not the main reasons as many of these new proposals are technically sound. In this paper, we take an economic perspective and seek to answer: Why most new Internet architectures failed to be deployed? What makes a new architecture easier to deploy? We develop a game-theoretic model to characterize the outcome of an architecture's deployment through the equilibrium of ISP's decisions. We also use our model to explain the deploying outcomes of IPv6, DiffServ, CDN, etc., and the ""Internet flattening phenomenon"". Furthermore, one can use our model to predict the deployability of new architectures such as NDN, XIA, and compare the deployability of competing architectures. Our study also suggests that the architectures which try to make a fresh start may have a low deployability, unless they have efficient incremental deployment mechanisms or one introduces a centralized coordinator to help the deployment."
Rate of Convergence of Increasing Path-Vector Routing Protocols.,"A good measure of the rate of convergence of path-vector protocols is the number of synchronous iterations required for convergence in the worst case. From an algebraic perspective, the rate of convergence depends on the expressive power of the routing algebra associated with the protocol. For example in a network of n nodes, shortest-path protocols are guaranteed to converge in O(n) iterations. In contrast the algebra underlying the Border Gateway Protocol (BGP) is in some sense too expressive and the protocol is not guaranteed to converge. There is significant interest in finding well-behaved algebras that still have enough expressive power to satisfy network operators. Recent theoretical results have shown that by constraining routing algebras to those that are ""strictly increasing"" we can guarantee the convergence of path-vector protocols. Currently the best theoretical worst-case upper bound for the convergence of such algebras is O(n!) iterations. However in practice it is difficult to find examples that do not converge in n iterations. In this paper we close this gap. We first present a family of network configurations that converges in Î˜(n
<sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup>
) iterations, demonstrating that the worst case is Î©(n
<sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup>
) iterations. We then prove that path-vector protocols with a strictly increasing algebra are guaranteed to converge in O(n
<sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup>
) iterations. Together these results establish a tight Î˜(n
<sup xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">2</sup>
) bound. This is another piece of the puzzle in showing that ""strictly increasing"" is, at least on a technical level, a reasonable constraint for practical policy-rich protocols."
Shifter: A Consistent Multicast Routing Update Scheme in Software-Defined Networks.,"Consistent routing update based on Software-Defined Networks (SDN) is a complicated problem due to the asynchronous and distributed data plane. Existing ordered update approaches mostly focus on the consistent routing update problem for unicast other than multicast, which should guarantee two consistencies, drop-freeness and duplicate-freeness. In this paper, we propose Shifter, a novel dynamic ordered update scheme for consistent multicast routing update based on SDN to guarantee both consistencies. Shifter advocates configuring inport match field in the forwarding rules to avoid duplicate. In order to guarantee drop-freeness, Shifter employs a dependency graph to dynamically schedule update operations, and uses a greedy solution to solve a subproblem named Replace Operation Tree Migration Problem (ROTMP). We conduct simulations to evaluate Shifter and find that Shifter can give a near optimal solution of ROTMP with very few rounds and little runtime for multicast routing update scenarios. To the best of our knowledge, Shifter is the first ordered update scheme to guarantee the two consistencies simultaneously."
Canon: Exploiting Channel Diversity for Reliable Parallel Decoding in Backscatter Communication.,"Backscatter communication, due to its low energy consumption, attract a broad range of applications. The throughput of such low-power communication is however limited. Parallel backscatter is deemed as a promising technique for improving the overall throughput by enabling concurrent transmissions of the backscattering tags. The state-of-the-art approaches for parallel backscatter assume that all the states of the collided signals are distinguishable in the In-phase and Quadrature (IQ) signal plane. In this paper, we disclose the superclustering phenomenon that makes the assumption untenable and significantly degrades the overall performance. Moreover, we observe that the indistinguishable states at different channels are not the same due to the intrinsic channel diversity. Motivated by the observation, we propose Canon, an approach that exploits the channel diversity of the backscatter tags for reliable parallel decoding. In Canon, we address two critical challenges: (i) designing the Multi-Carrier Backscatter (MCB) module to extract the collided signals simultaneously from multiple channels, (ii) designing the Multi-Channel Cluster Union (MCCU) algorithm to distinguish each state of the collided signals. The experiments demonstrate that Canon can achieve over 10 times higher throughput than the state-of-the-art approaches."
Distributed Spectrum Sharing for Enterprise Powerline Communication Networks.,"As powerline communication (PLC) technology does not require dedicated cabling and network setup, it can be used to easily connect multitude of IoT devices deployed in enterprise environments for sensing and control related applications. IEEE has standardized the PLC protocol in IEEE 1901, also known as HomePlug AV (HPAV), which is widely adopted PLC standard. A key weakness of HPAV protocol is that it does not support any spectrum sharing strategies. Currently, each link in an HPAV PLC network operates over the whole available spectrum, and only one link can operate at any time within a single collision domain. We conducted a large scale measurement study using commodity HPAV PLC devices and analyzed channel characteristics of PLC networks in a real enterprise environment across space, time, and spectral dimensions. Based on our findings, we propose a distributed spectrum sharing technique for enterprise PLC networks, and show that fine-grained distributed spectrum sharing on top of current HPAV MAC protocols can boost the aggregated and per-link throughput by up to 60% and 250% respectively, by allowing multiple PLC links to communicate concurrently, while requiring a few modifications to the existing HPAV PLC devices and protocols."
"If you can't Beat Them, Augment Them: Improving Local WiFi with Only Above-Driver Changes.","The basic MAC mechanisms in IEEE 802.11 (WiFi) have remained largely unchanged for over 20 years. In this paper, we argue that the prevalence of WiFi makes it almost impossible to improve its performance through changes that require modifying hardware, firmware, or drivers. New applications, however, continue to exert novel performance demands. We suggest that changes should be developed as augmentation-only solutions through above-driver, kernel-level software modifications. An augmentation-only solution needs to maintain inter-operability and afford transparency in performance to existing WiFi devices, as well as enable minimum overhead upgradability. Our goal is to demonstrate the feasibility of MAC augmentation according to these principles. To this end, we leverage soft scheduling, where nodes are asked for a best-effort attempt to adhere to a given schedule. We allow the soft scheduler to coexist with and work at a different time scale from WiFi's Distributed Coordination Function (DCF); allowing it to reduce the time nodes spend contending for the medium while allowing DCF to handle only missed schedule slots and schedule divergence. We present a new Soft Token Passing Protocol (STPP) as an instance of this family of Soft Scheduling Protocols. We then show how STPP can be made part of a MAC protocol with specific performance improvement goals by developing the Wireless Low-Latency Local Links (WL4) system. We evaluate WL4 on a five node microbenchmark and quantify the system's overhead on network throughput and latency. We show that soft scheduling, via STPP, enables WL4 to adhere to our augmentation principles while improving the latency within the system."
Named Data Networking with Programmable Switches.,"The Internet today is mainly used for distributing content, in a fundamental departure from its original goal of enabling communication between endpoints. As a response to this change, Named Data Networking (NDN) is a new architecture rooted on the concept of naming data, in contrast to the original paradigm based on naming hosts. This radical architectural shift results in packet processing in NDN to differ substantially from IP. As a consequence, current network equipment cannot be seamlessly extended to offer NDN data-plane functions. To address this challenge, available NDN router solutions are usually software-based, and even the highly-optimised designs tailored to specific hardware platforms present limited performance, hindering adoption. In addition, these tailor-made solutions are hardly reusable in research and production networks. The emergence of programmable switching chips and of languages to program them, like P4, brings hope for the state of affairs to change. In this paper, we present the design of an NDN router written in P4. We improve over the state-of-the-art solution by extending the NDN functionality, and by addressing its scalability limitations. A preliminary evaluation of our open-source solution running on a software target demonstrates its feasibility."
Consensus for Non-volatile Main Memory.,"Traditionally, computer storage has been separated into a hierarchy based on response time, volatility, and cost of media. This tiering is undergoing a significant upheaval as a new breed of memory technologies, termed Storage Class Memories (SCM), now make it feasible to replace several tiers of the hierarchy with a single, cost-effective, uniform type of memory/storage. To make large-scale SCM deployments practical, however, memory system designers will first need to solve the problem of how to guard against unavoidable storage wear-out and failures-problems traditionally absent from ""main memory"" and handled by software at leisurely timescales in the domain of storage. In this paper, we propose a novel approach to providing fault tolerance in SCM-based main memory. Our key insight is to treat memory as a distributed storage system and rely on data replication and a consensus protocol to keep the replicas consistent. Separate memory instances store replicated copies of the data, and we use a programmable network interconnect to provide fast consensus between the memory instances. Our initial experiments using software memory controller emulation demonstrate reasonable overhead over local memory reads and show great promise as scalable main memory."
Transparent Edge Gateway for Mobile Networks.,"Advances in software-defined networking (SDN) enable a wave of innovation in a wide selection of networks ranging from data center networks to WAN. While existing standard bodies for mobile networks define stringent requirements, they too are embracing the flexibility of SDN in defining the specifications of the next generation of mobile networks. Mobile edge computing (MEC), in particular, is an emerging architecture to bring virtualized network functions and programmable network devices closer to the user. For instance, delay-sensitive or bandwidth-hungry computing resources are moved to the edge of the radio access network (RAN) to provide low latency computation and/or content for users while alleviating the backhaul pressure for network operators. In this paper, we propose an edge gateway (EGW) in the MEC that enables offloading of computation and storage resources to the edge of mobile networks. The EGW is backward compatible with components and protocols of LTE networks and does not require any modification in the user equipment, LTE software, or offloaded resources. We have designed and implemented the EGW using P4 language and verified its operation on a small testbed using a low-end P4 target and a reference LTE protocol stack."
Stateless Load-Aware Load Balancing in P4.,"Leveraging the performance opportunities offered by programmable hardware, stateless load-balancing architectures allowing line-rate processing are appealing. Moreover, it has been demonstrated that significantly fairer load-balancing can be achieved by an architecture that considers the actual load of application instances when dispatching connection requests. Architectures which maintain per-connection state for resiliency and/or track application load state for fairness are, however, at odds with hardware-imposed memory constraints. Thus, a desirable load-balancer for programmable hardware would be both stateless and able to dispatch queries to application instances according to their current load. This paper presents SHELL, a stateless application-aware load-balancer combining (i) a power-of-choices scheme using IPv6 Segment Routing to dispatch new flows to a suitable application instance from among multiple candidates, and (ii) the use of a covert channel to record/report which flow was assigned to which candidate in a stateless fashion. In addition, consistent hashing versioning is used to ensure that connections are maintained to the correct application instance, using Segment Routing to ""browse"" through the history when needed. The stateless design of SHELL makes it suitable for hardware implementation, and this paper describes the implementation of a P4-NetFPGA prototype. A performance evaluation of this SHELL implementation demonstrates throughput and latency characteristics comparable to other stateless load-balancing implementations, while enabling application instance-load-aware dispatching and significantly increasing per-connection consistency resiliency."
P4LLVM: An LLVM Based P4 Compiler.,"We propose P4LLVM, an LLVM based P4 compiler for achieving better optimizations to improve the runtime performance of the network. The front-end of P4LLVM converts P4-16's code to LLVM's Intermediate Representation (IR). This IR is passed through various optimizations of LLVM and is translated to JSON for targeting a BMV2 Switch. We show the performance improvements obtained by running LLVM optimization passes in P4LLVM when compared to P4C."
pcube: Primitives for Network Data Plane Programming.,"P4 is a domain specific language to configure packet processing pipelines in programmable dataplane switches, and is a powerful idea towards realizing the goal of flexible software-defined networks. This paper presents pcube, a framework that provides a set of primitives to simplify the development of P4-based dataplane applications. pcube provides primitives for loops, summations, and other common operations on indexed state variables, which can be embedded within P4 code and unrolled by the pcube preprocessor. pcube also provides primitives to synchronize state variables across switches in distributed dataplane applications, which are automatically translated into P4 code to send and receive synchronization messages across multiple switches by pcube. We build example dataplane applications such as a distributed load balancer in our framework, and show that using pcube reduces the programming effort (in term of lines of code) significantly-by a factor of up to 5.4x."
Network Coding for Critical Infrastructure Networks.,"The applications in the critical infrastructure systems pose simultaneous resilience and performance requirements to the underlying computer network. To meet such requirements, the networks that use the store-and-forward paradigm poses stringent conditions on the redundancy in the network topology and results in problems that becoming computationally challenging to solve at scale. However, with the advent of programmable data-planes, it is now possible to use linear network coding (NC) at the intermediate network nodes to meet resilience requirements of the applications. To that end, we propose an architecture that realizes linear NC in programmable networks by decomposing the linear NC functions into the atomic coding primitives. We designed and implemented the primitives using the features offered by the P4 ecosystem. Using an empirical evaluation, we show that the theoretical gains promised by linear network coding can be realized with a per-packet processing cost."
ARP-P4: A Hybrid ARP-Path/P4Runtime Switch.,"This paper presents ARP-P4, a hybrid switch based on a local ARP-Path control plane written in P4, but maintaining legacy P4 Runtime control plane capabilities. Its main purpose is to study the readiness of P4 to perform directly local control actions at the data plane, such as the required ones for the ARP-Path protocol. Thus, ARP-P4 defines a data plane that forwards any ingress packet locally via ARP-Path or remotely via P4 Runtime installed rules through an SDN controller. Finally, we discuss the current limitations of P4 non-standard externs to interact with P4 Runtime to develop autonomous capabilities."
"One for All, All for One: A Heterogeneous Data Plane for Flexible P4 Processing.","The P4 community has recently put significant effort to increase the diversity of targets on which P4 programs can be implemented. These include fixed function and programmable ASICs, FPGAs, NICs, and CPUs. However, P4 programs are written according to the set of functionalities supported by the target for which they are compiled. For instance, a P4 program targeting a programmable ASIC cannot be extended with user-defined processing modules, which limits the flexibility and the abstraction of P4 programs. To address these shortcomings, we propose a heterogeneous P4 programmable data plane comprised of different targets that together appear as a single logical unit. The proposed data plane broadens the range of functionalities available to P4 programmers by combining the strength of each target. We demonstrate the feasibility of the proposed P4 data plane by coupling an FPGA with a soft switch which emulates a programmable ASIC. The proposed data plane is demonstrated with the implementation of a simplified L2 switch. The emulated ASIC match-table capacity is extended by the FPGA by an order of magnitude.The FPGA also integrates a proprietary module using a P4 extern."
Using P4 to Enable Scalable Intents in Software Defined Networks.,"When designing Software Defined Networks (SDNs), there is a risk that the additional abstractions available can result in reduced scalability and performance. One such abstraction, intents, are a way in which network administrators can express policies rather than having to define specific forwarding rules. This provides a benefit to administrators in allowing automatic network reconfiguration and fault tolerance. In this paper, we highlight the performance overheads associated with the intents framework from a popular SDN controller, ONOS. We propose a novel prototype that leverages source-based routing and programmable data planes using P4 in order to reduce the overheads of intent-based forwarding."
Verification of Generated RTL from P4 Source Code.,"The P4 is a general and platform agnostic language for the description of packet processing functionality. So far it is being supported by a number of technology companies which provided a way for programming of their devices using the P4 language. One of possible platforms is a SmartNIC - a Field Programmable Gate Array (FPGA) device which connects flexibility with high performance into a compact package. FPGA circuits are typically programmed in a Hardware Description Language (HDL) like VHDL or Verilog. These languages are hard to learn for novices and the development of a network device is very time consuming. Therefore, researchers around the world are finding a way how to automate the translation process from P4 to HDL language because such approach allows easy and fast programming of FPGA SmartNICs to a big audience of network experts. There are currently available three main compilers for the translation of P4 source to HDL - SDNet P4FPGA and P4-to-VHDL. In our best knowledge, all mentioned compilers don't provide any automated test environment which can be used repeatedly for different P4 programs. In other words, the verification environment has to be written by hand for each P4 program. Our work demonstrates a possible solution for automated verification of generated Register Transfer Level (RTL) description of a packet processing device from provided P4 source code."
Hardware-Accelerated Firewall for 5G Mobile Networks.,"The evolution from the current Fourth-Generation (4G) networks to the emerging Fifth-Generation (5G) technologies implies significant changes in the architecture and poses demanding requirements on network infrastructures. One of the Key Performance Indicators (KPIs) in 5G is to ensure a secure network with zero downtime. In this paper, we focus on the provisioning of protection capabilities for 5G infrastructures. Our objective is to implement a new 5G firewall that allows the detection, differentiation and selective blocking of 5G network traffic in the edge-to-core network segment of a 5G infrastructure, using a hardware-accelerated framework based on Field Programmable Gate Arrays (FPGA), developed using the P4 language. The proposed 5G firewall has been prototyped with the new capabilities proposed empirically validated."
Switch ASIC Programmability in Hybrid Mode.,"Programmable ASIC technology enables the switching data plane to rapidly support emergent technologies such as VNF offloading, custom tunneling and in-band telemetry. We propose a new approach for a ""hybrid mode"" of ASIC programmability, which maintains a discrete legacy hardware pipeline and control functions (e.g. routing, bridging) while providing a way to extend it. This places requirements on the switching hardware, programming language, data plane APIs and the network OS in order to achieve this goal. In this paper we present two hardware agnostic hybrid mode applications using a Mellanox programmable switch ASIC, P4-16 programming language, SAI flexible APIs and the SONIC Open Network OS and Linux TC. Also applications based on the Onyx OS and Spectrum SDK is discussed as a hardware specific example."
