Session details: Session 6,No abstract available.
Effectiveness of Delaying Timestamp Computation,"Practical algorithms for determining causality by assigning timestamps to events have focused on online algorithms, where a permanent timestamp is assigned to an event as soon as it is created. We address the problem of reducing size of the timestamp by utilizing the underlying topology (which is often not fully connected since not all processes talk to each other) and deferring the assignment of a timestamp to an event for a suitably chosen period of time after the event occurs. Specifically, we focus on inline timestamps, which are a generalization of offline timestamps that are assigned after the computation terminates. We show that for a graph with vertex cover VC, it is possible to assign inline timestamps which contains only 2|VC|+2 elements."
Symmetry Breaking with Noisy Processes,"Biology and computer science intersect at the problem of symmetry breaking, which is relevant in both fields. Accordingly, in recent years, distributed algorithm theorists have studied symmetry breaking problems in models inspired by biology to help provide insight into the capabilities and constraints of this natural process. A potential shortcoming of these models, however, is that they execute distributed algorithms precisely as specified. In nature, where computation is often implemented by messy analog systems, this precision cannot necessarily be guaranteed. Motivated by this observation, in this paper we present a general method for injecting computational noise into any distributed system model that describes processes as interacting state machines. Our method captures noise as a force that can cause state machines to transition to the wrong state. We combine this formalization of noise with the beeping models that have been a popular target of recent work on bio-inspired symmetry breaking. We produce new upper and lower bounds for both single hop and multihop models---studying leader election in the former and the maximal independent set problem in the latter. These bounds introduce new techniques for achieving robustness to noise, and identify some fundamental limits in this pursuit. We argue that both our general approach and specific results can help advance the productive relationship between biology and algorithm theory."
The Power of Choice in Priority Scheduling,"Consider the following random process: we are given n queues, into which elements of increasing labels are inserted uniformly at random. To remove an element, we pick two queues at random, and remove the element of lower label (higher priority) among the two. The cost of a removal is the rank of the label removed, among labels still present in any of the queues, that is, the distance from the optimal choice at each step. Variants of this strategy are prevalent in state-of-the-art concurrent priority queue implementations. Nonetheless, it is not known whether such implementations provide any rank guarantees, even in a sequential model. We answer this question, showing that this strategy provides surprisingly strong guarantees: Although the single-choice process, where we always insert and remove from a single randomly chosen queue, has degrading cost, going to infinity as we increase the number of steps, in the two choice process, the expected rank of a removed element is O(n) while the expected worst-case cost is O(n log n). These bounds are tight, and hold irrespective of the number of steps for which we run the process. The argument is based on a new technical connection between ""heavily loaded"" balls-into-bins processes and priority scheduling. Our analytic results inspire a new concurrent priority queue implementation, which improves upon the state of the art in terms of practical performance."
A Template for Implementing Fast Lock-free Trees Using HTM,"Algorithms that use hardware transactional memory (HTM) must provide a software-only fallback path to guarantee progress. The design of the fallback path can have a profound impact on performance. If the fallback path is allowed to run concurrently with hardware transactions, then hardware transactions must be instrumented, adding significant overhead. Otherwise, hardware transactions must wait for any processes on the fallback path, causing concurrency bottlenecks, or move to the fallback path. We introduce an approach that combines the best of both worlds. The key idea is to use three execution paths: an HTM fast path, an HTM middle path, and a software fallback path, such that the middle path can run concurrently with each of the other two. The fast path and fallback path do not run concurrently, so the fast path incurs no instrumentation overhead. Furthermore, fast path transactions can move to the middle path instead of waiting or moving to the software path. We demonstrate our approach by producing an accelerated version of the tree update template of Brown et al., which can be used to implement fast lock-free data structures based on down-trees. We used the accelerated template to implement two lock-free trees: a binary search tree (BST), and an (a,b)-tree (a generalization of a B-tree). Experiments show that, with 72 concurrent processes, our accelerated ($a,b$)-tree performs between 4.0x and 4.2x as many operations per second as an implementation obtained using the original tree update template."
Adding Concurrency to Smart Contracts,"Modern cryptocurrency systems, such as Ethereum, permit complex financial transactions through scripts called smart contracts. These smart contracts are executed many, many times, always without real concurrency. First, all smart contracts are serially executed by miners before appending them to the blockchain. Later, those contracts are serially re-executed by validators to verify that the smart contracts were executed correctly by miners. Serial execution limits system throughput and fails to exploit today's concurrent multicore and cluster architectures. Nevertheless, serial execution appears to be required: contracts share state, and contract programming languages have a serial semantics."
