Session details: Session 8,No abstract available.
Greedy Routing and the Algorithmic Small-World Phenomenon,"The algorithmic small-world phenomenon, empirically established by Milgram's letter forwarding experiments from the 60s, was theoretically explained by Kleinberg in 2000. However, from today's perspective his model has several severe shortcomings that limit the applicability to real-world networks. In order to give a more convincing explanation of the algorithmic small-world phenomenon, we study decentralized greedy routing in a more flexible random graph model (geometric inhomogeneous random graphs) which overcomes all previous shortcomings. Apart from exhibiting good properties in theory, it has also been extensively experimentally validated that this model reasonably captures real-world networks. In this model, the greedy routing protocol is purely distributed as each vertex only needs to know information about its direct neighbors. We prove that it succeeds with constant probability, and in case of success almost surely finds an almost shortest path of length Θ(log log n), where our bound is tight including the leading constant. Moreover, we study natural local patching methods which augment greedy routing by backtracking and which do not require any global knowledge. We show that such methods can ensure success probability 1 in an asymptotically tight number of steps."
Triangle Finding and Listing in CONGEST Networks,"Triangle-free graphs play a central role in graph theory, and triangle detection (or triangle finding) as well as triangle enumeration (triangle listing) play central roles in the field of graph algorithms. In distributed computing, algorithms with sublinear round complexity for triangle finding and listing have recently been developed in the powerful CONGEST clique model, where communication is allowed between any two nodes of the network. In this paper we present the first algorithms with sublinear complexity for triangle finding and triangle listing in the standard CONGEST model, where the communication topology is the same as the topology of the network. More precisely, we give randomized algorithms for triangle finding and listing with round complexity O(n2/3(log n)2/3) and O(n3/4log n), respectively, where n denotes the number of nodes of the network. We also show a lower bound Ω(n1/3/log n) on the round complexity of triangle listing, which also holds for the CONGEST clique model."
Asynchronous Shared Channel,"In this work we address the question whether a simple shared channel could be efficiently utilized, that is, with a constant throughput and linear packet latency. A shared channel (also called a multiple access channel), introduced nearly 50 years ago in the context of the Ethernet [36], is among the most popular and widely studied models of communication and distributed computing. In a nutshell, a number of stations is able to communicate by transmitting and listening to a shared channel, and a message is successfully delivered to all stations if and only if its source station is the only transmitter at a time. Despite of a vast amount of work in the last decades, many fundamental questions remain open, such as: What is the impact of asynchrony on channel utilization? How important is the knowledge/estimate of the number of contenders? Could non-adaptive protocols (i.e., random codes) be asymptotically as efficient as adaptive protocols? In this work we present a broad picture of results answering the above mentioned questions for a fundamental problem of contention resolution, in which each of the contending stations needs to broadcast successfully its message. We show that adaptive algorithms or algorithms with the knowledge of contention size k (i.e., random codes with knowledge of k) achieve constant channel throughput and linear message latency even for very weak channels, i.e., with feedback restricted to simple acknowledgments and in the absence of synchronization. This asymptotically optimal performance cannot be extended to other settings --- we prove that there is no non-adaptive algorithm without the knowledge of contention size k achieving throughput \omega((\log\log k)^2/(\log k)) and/or admitting latency o(k\log k/(\log\log k)^2). This means, in particular, that coding (even random) with acknowledgments is not very efficient on a shared channel without synchronization or estimate of contention size. We also present a non-adaptive algorithm with no knowledge of contention size that almost matches these two complexities. More specifically, it achieves latency O(k\log^2 k) and channel utilization \Omega(1/\log^2 k) even if stations do not switch off after successful transmissions (and thus, could disturb other stations in succeeding), and could be improved by factor \Theta(\log\log k) if stations switch off after acknowledgment. Despite the absense of a collision detection mechanism, our algorithms are also efficient in terms of energy. The maximum number of channel accesses (including transmissions and listenings) for our non-adaptive solutions, with and without knowledge of k, is respectively O(\log k) and O(\log^2 k) whp. Regarding the adaptive algorithm, we argue that a simple modification of our protocol preserves constant throughput and linear latency while achieving O(\log k) maximum number of channel accesses per station whp."
Self-organized Segregation on the Grid,"We consider an agent-based model in which two types of agents interact locally over a graph and have a common intolerance threshold τ for changing their types with exponentially distributed waiting times. The model is equivalent to an unperturbed Schelling model of self-organized segregation, an Asynchronous Cellular Automata (ACA) with extended Moore neighborhoods, or a zero-temperature Ising model with Glauber dynamics, and has applications in the analysis of social and biological networks, and spin glasses systems. Some rigorous results were recently obtained in the theoretical computer science literature, and this work provides several extensions. We enlarge the intolerance interval leading to the formation of large segregated regions of agents of a single type from the known size ε>0 to size ~0.134. Namely, we show that for 0.433 < τ < 1/2 (and by symmetry 1/2<τ<0.567), the expected size of the largest segregated region containing an arbitrary agent is exponential in the size of the neighborhood. We further extend the interval leading to large segregated regions to size ~0.312 considering ""almost segregated"" regions, namely regions where the ratio of the number of agents of one type and the number of agents of the other type vanishes quickly as the size of the neighborhood grows. In this case, we show that for 0.344 < τ ≤ 0.433 (and by symmetry for 0.567 ≤ τ<0.656) the expected size of the largest almost segregated region containing an arbitrary agent is exponential in the size of the neighborhood. This behavior is reminiscent of supercritical percolation, where small clusters of empty sites can be observed within any sufficiently large region of the occupied percolation cluster. The exponential bounds that we provide also imply that complete segregation, where agents of a single type cover the whole grid, does not occur with high probability for p=1/2 and the range of tolerance considered."
Brief Announcement: Efficient Self-Stabilizing 1-Maximal Matching Algorithm for Arbitrary Networks,"We present a new self-stabilizing 1-maximal matching algorithm that works under the distributed unfair daemon for arbitrarily shaped networks. Our algorithm is efficient (its stabilization time is O(e) moves, where e denotes the number of edges in the network). Besides, our algorithm is optimal with respect to identifiers locality (we assume node identifiers are distinct up to distance three, a necessary condition to withstand arbitrary networks)."
Brief Announcement: Secure Self-Stabilizing Computation,"Self-stabilization refers to the ability of systems to recover after temporal violations of conditions required for their correct operation. Such violations may lead the system to an arbitrary state from which it should automatically recover. Today, beyond recovering functionality, there is a need to recover security and confidentiality guarantees as well. To the best of our knowledge, there are currently no self-stabilizing protocols that also ensure recovering confidentiality, authenticity, and integrity properties. Specifically, self-stabilizing systems are designed to regain functionality which is, roughly speaking, desired input output relation, ignoring the security and confidentiality of computation and its state. Distributed (cryptographic) protocols for generic secure and privacy-preserving computation, e.g., secure Multi-Party Computation (MPC), usually ensure secrecy of inputs and outputs, and correctness of computation when the adversary is limited to compromise only a fraction of the components in the system, e.g., the computation is secure only in the presence of an honest majority of involved parties. While there are MPC protocols that are secure against a dishonest majority, in reality, the adversary may compromise all components of the system for a while; some of the corrupted components may then recover, e.g., due to security patches and software updates, or periodical code refresh and local state consistency check and enforcement based on self-stabilizing hardware and software techniques. It is currently unclear if a system and its state can be designed to always fully recover following such individual asynchronous recoveries. This paper introduces Secure Self-stabilizing Computation which answers this question in the affirmative. Secure self-stabilizing computation design ensures that secrecy of inputs and outputs, and correctness of the computation are automatically regained, even if at some point the entire system is compromised. We consider the distributed computation task as the implementation of virtual global finite satiate machine (FSM) to present commonly realized computation. The FSM is designed to regain consistency and security in the presence of a minority of Byzantine participants, e.g., one third of the parties, and following a temporary corruption of the entire system. We use this task and settings to demonstrate the definition of secure self-stabilizing computation. We show how our algorithms and system autonomously restore security and confidentiality of the computation of the FSM once the required corruption thresholds are again respected."
Stateless Computation,"We present and explore a model of stateless and self-stabilizing distributed computation, inspired by real-world applications such as routing on today's Internet. Processors in our model do not have an internal state, but rather interact by repeatedly mapping incoming messages (""labels"") to outgoing messages and output values. While seemingly too restrictive to be of interest, stateless computation encompasses both classical game-theoretic notions of strategic interaction and a broad range of practical applications (e.g., Internet protocols, circuits, diffusion of technologies in social networks). Our main technical contribution is a general impossibility result for stateless self-stabilization in our model, showing that even modest asynchrony (with wait times that are linear in the number of processors) can prevent a stateless protocol from reaching a stable global configuration. Furthermore, we present hardness results for verifying stateless self-stabilization. We also address several aspects of the computational power of stateless protocols. Most significantly, we show that short messages (of length that is logarithmic in the number of processors) yield substantial computational power, even on very poorly connected topologies."
