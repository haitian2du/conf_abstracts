Session details: Session VI: Better Mobile Interfaces,No abstract available.
Expansion of Human-Phone Interface By Sensing Structure-Borne Sound Propagation,"ForcePhone is a novel system that enables commodity phones to recognize the force applied to their touch screen and body. Researchers have shown the usefulness and importance of this expressive input interface (especially for the one-hand operation), but this advanced function has not yet been realized and deployed in most state-of-the-art smartphones. Instead of employing or augmenting specialized/proprietary sensors, ForcePhone uses only the phone's built-in sensors to measure the applied force via a physical property called structure-borne sound propagation. ForcePhone has been implemented and evaluated on both iOS and Android phones. Multiple demo applications, such as getting the option menu by hard-pressing a button or surfing the previous webpage by squeezing the phone, have been implemented and tested successfully. The estimated force is shown highly correlated to the real applied force and the estimation error is less than 54g when the phone is stationary. Users can easily control the applied force at two different levels with a 97% accuracy. Moreover, ForcePhone can detect the squeeze of the phone body with a higher than 90% accuracy. Most participants in our usability study were able to master the ForcePhone-based apps and find them very useful."
FlashBack: Immersive Virtual Reality on Mobile Devices via Rendering Memoization,"Virtual reality head-mounted displays (VR HMDs) are attracting users with the promise of full sensory immersion in virtual environments. Creating the illusion of immersion for a near-eye display results in very heavy rendering workloads: low latency, high framerate, and high visual quality are all needed. Tethered VR setups in which the HMD is bound to a powerful gaming desktop limit mobility and exploration, and are difficult to deploy widely. Products such as Google Cardboard and Samsung Gear VR purport to offer any user a mobile VR experience, but their GPUs are too power-constrained to produce an acceptable framerate and latency, even for scenes of modest visual quality."
uLink: Enabling User-Defined Deep Linking to App Content,"Web deep links are instrumental to many fundamental user experiences such as navigating to one web page from another, bookmarking a page, or sharing it with others. Such experiences are not possible with individual pages inside mobile apps, since historically mobile apps did not have links equivalent to web deep links. Mobile deep links, introduced in recent years, still lack many important properties of web deep links. Unlike web links, mobile deep links need significant developer effort, cover a small number of predefined pages, and are defined statically to navigate to a page for a given link, but not to dynamically generate a link for a given page. We propose uLink, a novel deep linking mechanism that addresses these problems. uLink is implemented as an application library, which transparently tracks data- and UI-event-dependencies of app pages, and encodes the information in links to the pages; when a link is invoked, the information is utilized to recreate the target page quickly and accurately. uLink also employs techniques, based on static and dynamic analysis of the app, that can provide feedback to users about whether a link may break in the future due to, e.g., modifications of external resources such as a file the link depends on. We have implemented uLink on Android. Our evaluation with 34 (of 1000 most downloaded) Android apps shows that compared to existing mobile deep links, uLink requires minimal developer effort, achieves significantly higher coverage, and can provide accurate user feedback on a broken link."
